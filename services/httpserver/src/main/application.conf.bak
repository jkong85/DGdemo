#dg {
#  # mapping-strategy.implementation = "org.eclipse.ditto.services.gateway.starter.service.util.GatewayMappingStrategy"
#
#  cluster {
#    become-leader = false
#    instance-index = ${?INSTANCE_INDEX}
#  }
#
#  services-utils-config.mongodb.options {
#    ssl = false
#    w = 1
#  }
#
#  httpserver {
#    http {
#      # InetAddress.getLocalHost.getHostAddress is used if empty
#      hostname = ""
#      hostname = ${?HOSTNAME}
#      hostname = ${?BIND_HOSTNAME}
#      port = 8080
#      port = ${?HTTP_PORT}
#      port = ${?PORT}
#
#      schema-versions = [1, 2]
#      # override schema-versions via system properties, e.g.: -Dditto.gateway.http.schema-versions.0=1 -Dditto.gateway.http.schema-versions.1=2
#    }
#
#    cluster {
#      # as a rule of thumb: should be factor ten of the amount of cluster nodes available
#      # be aware that it must be the same as for all other services (e.g. search-updater)
#      number-of-shards = 30
#      number-of-shards = ${?CLUSTER_NUMBER_OF_SHARDS}
#
#      # enables the majority check that solves network partitions automatically
#      majority-check.enabled = false
#      majority-check.enabled = ${?CLUSTER_MAJORITY_CHECK_ENABLED}
#
#      # the delay after which the cluster majority is checked
#      majority-check.delay = 30s
#      majority-check.delay = ${?CLUSTER_MAJORITY_CHECK_DELAY}
#    }
#
#    websocket {
#      # the max queue size of how many inflight Commands a single Websocket client can have
#      subscriber.backpressure-queue-size = 100
#      subscriber.backpressure-queue-size = ${?WS_SUBSCRIBER_BACKPRESSURE}
#
#      # the max buffer size of how many outstanding CommandResponses and Events a single Websocket client can have
#      # additionally CommandResponses and Events are dropped if this size is reached
#      publisher.backpressure-buffer-size = 200
#      publisher.backpressure-buffer-size = ${?WS_PUBLISHER_BACKPRESSURE}
#    }
#
#    enforcer {
#      # the interval of how long to keep an "inactive" enforcer in memory:
#      cache.interval = 2h
#      cache.interval = ${?ENFORCER_CACHE_INTERVAL} # may be overridden with this environment variable
#
#      # the interval of when to manually sync the underlying permission structure (policy or acl) of the enforcer
#      sync.interval = 15m
#      sync.interval = ${?ENFORCER_SYNC_INTERVAL} # may be overridden with this environment variable
#
#      # the internal timeout when retrieving the Policy or the ACL or when waiting for a CommandResponse
#      internal.ask.timeout = 5s
#      internal.ask.timeout = ${?ENFORCER_INTERNAL_ASK_TIMEOUT} # may be overridden with this environment variable
#    }
#
#    message {
#      default-timeout = 10s
#      max-timeout = 1m
#
#      http-header-blacklist = [
#        "authorization",
#        "raw-request-uri",
#        "cache-control",
#        "connection",
#        "timeout-access",
#        "read-subjects",
#        "origin",
#        "source"
#      ]
#    }
#
#    claim-message {
#      default-timeout = 1m
#      max-timeout = 10m
#    }
#
#    dns {
#      # DNS server to use for looking up services
#      address = none
#      address = ${?DNS_SERVER} # may be overridden with this environment variable
#    }
#
#    authentication {
#      # configures HTTP for different authentication mechanisms: IM3, JWT (e.g. Google), ...
#      http {
#        # proxy config
#        proxy {
#          enabled = false
#          enabled = ${?AUTH_HTTP_PROXY_ENABLED}
#
#          host = ${?AUTH_HTTP_PROXY_HOST}
#          port = ${?AUTH_HTTP_PROXY_PORT}
#          username = ${?AUTH_HTTP_PROXY_USERNAME}
#          password = ${?AUTH_HTTP_PROXY_PASSWORD}
#        }
#      }
#
#      dummy {
#        # enable/disable dummy authentication (for dev purposes)
#        enabled = false
#        enabled = ${?ENABLE_DUMMY_AUTH}
#      }
#    }
#
#    health-check {
#      enabled = true
#      enabled = ${?HEALTH_CHECK_ENABLED} # may be overridden with this environment variable
#      interval = 60s
#      service.timeout = 10s
#      service.timeout = ${?HEALTH_CHECK_SERVICE_TIMEOUT} # may be overridden with this environment variable
#
#      persistence {
#        enabled = true
#        enabled = ${?HEALTH_CHECK_PERSISTENCE_ENABLED} # may be overridden with this environment variable
#        timeout = 60s
#      }
#
#      cluster-roles = {
#        enabled = true
#        enabled = ${?HEALTH_CHECK_ROLES_ENABLED} # may be overridden with this environment variable
#
#        expected = [
#          "policies",
#          "things",
#          "things-search",
#          "gateway"
#        ]
#      }
#    }
#
#    devops {
#      securestatus = true
#      securestatus = ${?DEVOPS_SECURE_STATUS}
#    }
#
#    public-health {
#      secure = true
#      secure = ${?GATEWAY_PUBLIC_HEALTH_SECURE}
#      cache-timeout = 20s
#      cache-timeout = ${?GATEWAY_STATUS_HEALTH_EXTERNAL_TIMEOUT}
#    }
#
#    statsd {
#      hostname = ${?STATSD_PORT_8125_UDP_ADDR}
#      port = ${?STATSD_PORT_8125_UDP_PORT}
#    }
#
#    forcehttps = false
#    forcehttps = ${?FORCE_HTTPS}
#
#    enablecors = false
#    forcehttps = ${?ENABLE_CORS}
#
#    redirect-to-https = false
#    redirect-to-https = ${?REDIRECT_TO_HTTPS}
#    redirect-to-https-blacklist-pattern = "/api.*|/ws.*|/status.*"
#
#    cache {
#      publickeys {
#        maxentries = 32
#        expiry = 60m
#      }
#    }
#
#    things-aggregator {
#      single-retrieve-thing-timeout = 30s
#    }
#
#    policy-enforcer {
#      # the interval of how long to keep an "inactive" PolicyEnforcer in memory:
#      cache.interval = 2h
#      cache.interval = ${?POLICY_ENFORCER_CACHE_INTERVAL} # may be overridden with this environment variable
#
#      # the interval of when to manually sync the underlying Policy of the PolicyEnforcer
#      sync.interval = 15m
#      sync.interval = ${?POLICY_ENFORCER_SYNC_INTERVAL} # may be overridden with this environment variable
#
#      # the internal timeout when retrieving the Policy or the ACL or when waiting for a CommandResponse
#      internal.ask.timeout = 5s
#      internal.ask.timeout = ${?POLICY_ENFORCER_INTERNAL_ASK_TIMEOUT} # may be overridden with this environment variable
#    }
#  }
#}
#
#secrets {
#  devops_password = "foobar"
#  devops_password = ${?DEVOPS_PASSWORD}
#
#  public_health_password = "healthUserPw1!"
#  public_health_password = ${?PUBLIC_HEALTH_PASSWORD}
#}

akka {
  #loggers = ["akka.event.slf4j.Slf4jLogger"]
  #loglevel = "DEBUG"
  #logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"

  ## for log messages during the actor system is starting up and shutting down:
  #stdout-loglevel = "INFO"

  #log-config-on-start = off

  actor {
  #  provider = "akka.cluster.ClusterActorRefProvider"
  #  enable-additional-serialization-bindings = on

  #  # this is only intended for testing.
  #  serialize-messages = off
  #  serialize-creators = off

  ##  debug {
  #    lifecycle = on
  #  }

  #  deployment {
  #    /gatewayRoot/proxy {
  #      router = round-robin-pool
  #      # nr-of-instances = 5
  #      resizer {
  #        lower-bound = 5
  #        upper-bound = 100
  #        messages-per-resize = 50
  #      }
  #    }
  #    /gatewayRoot/proxy/aggregator {
  #      router = round-robin-pool
  #      # nr-of-instances = 5
  #      resizer {
  #        lower-bound = 5
  #        upper-bound = 100
  #        messages-per-resize = 50
  #      }
  #    }
  #  }

  #  default-dispatcher {
  #    fork-join-executor {
  #      parallelism-min = 4
  #      parallelism-factor = 3.0
  #      parallelism-max = 32
  #      parallelism-max = ${?DEFAULT_DISPATCHER_PARALLELISM_MAX}
  #    }
  #  }

    #serializers {
    #  json = "org.eclipse.ditto.services.utils.cluster.JsonifiableSerializer"
    #}

    #serialization-bindings {
    #  #"java.io.Serializable" = none # must not be set in order to get akka.cluster.sharding.ShardRegion$GetShardRegionStats$ serialized
    #  # Serialize Jsonifiable events with custom JSON serializer:
    #  "org.eclipse.ditto.model.base.json.Jsonifiable" = json
    #  "org.eclipse.ditto.model.base.exceptions.DittoRuntimeException" = json
    #}
  }

  #extensions = [
  #  "akka.cluster.pubsub.DistributedPubSub",
  #  "akka.cluster.ddata.DistributedData"
  #]

  #remote {
  #  log-remote-lifecycle-events = on
  #  netty.tcp {
  #    # InetAddress.getLocalHost.getHostAddress is used if empty
  #    hostname = ""
  #    hostname = ${?TCP_HOSTNAME}
  #    port = 2551
  #    port = ${?TCP_PORT}

  #    bind-hostname = ${?BIND_HOSTNAME}
  #    bind-port = ${?BIND_TCP_PORT}

  #    # maximum-frame-size = 128000b # this is the default
  #    maximum-frame-size = 10485760b # 10MB - things could get that big
  #    # send-buffer-size = 256000b # this is the default
  #    send-buffer-size = 20971520b # 20MB
  #    # receive-buffer-size = 256000b # this is the default
  #    receive-buffer-size = 20971520b # 20MB
  #  }
  #  watch-failure-detector.threshold = 12 # default 10
  #}

  #cluster {
  #  # Disable legacy metrics in akka-cluster.
  #  metrics.enabled = off

  #  # enable weakly up feature to allow members to join even if some members are unreachable
//    allow-weakly-up-members = on
//
//    # as fallback:
//    # seed-nodes = ["akka.tcp://ditto-cluster@"${akka.remote.netty.tcp.hostname}":"${akka.remote.netty.tcp.port}]
//    # seed-nodes = [ ] # otherwise they are dynamically set
//
//    sharding {
//      state-store-mode = ddata
//      use-dispatcher = "sharding-dispatcher"
//
//      role = "gateway"
//    }
//
//    roles = [
//      "gateway",
//      "thing-cache-aware",
//      "policy-cache-aware"
//    ]
//  }

  http {

    server {
      server-header = "" # default: akka-http/${akka.http.version}
      request-timeout = 60s # default: 20 s
      request-timeout = ${?REQUEST_TIMEOUT}
      max-connections = 4096 # default: 1024
      backlog = 100 # default: 100
      raw-request-uri-header = on # default: off

      parsing {
        max-uri-length = 8k # default: 2k
        max-content-length = 10m # default: 8m
        illegal-header-warnings = off # default: on
        error-logging-verbosity = simple # default: full
      }
    }

    host-connection-pool {
      # The maximum number of open requests accepted into the pool across all
      # materializations of any of its client flows.
      # Protects against (accidentally) overloading a single pool with too many client flow materializations.
      # Note that with N concurrent materializations the max number of open request in the pool
      # will never exceed N * max-connections * pipelining-limit.
      # Must be a power of 2 and > 0!
      max-open-requests = 1024 # default: 32

      # The time after which an idle connection pool (without pending requests)
      # will automatically terminate itself. Set to `infinite` to completely disable idle timeouts.
      idle-timeout = 60s # default: 30s
    }
  }
  stream {

    # Default materializer settings
    materializer {

      # Initial size of buffers used in stream elements
      initial-input-buffer-size = 4
      # Maximum size of buffers used in stream elements
      max-input-buffer-size = 16

      # Fully qualified config path which holds the dispatcher configuration
      # to be used by ActorMaterializer when creating Actors.
      # When this value is left empty, the default-dispatcher will be used.
      dispatcher = ""

      # Cleanup leaked publishers and subscribers when they are not used within a given
      # deadline
      subscription-timeout {
        # when the subscription timeout is reached one of the following strategies on
        # the "stale" publisher:
        # cancel - cancel it (via `onError` or subscribing to the publisher and
        #          `cancel()`ing the subscription right away
        # warn   - log a warning statement about the stale element (then drop the
        #          reference to it)
        # noop   - do nothing (not recommended)
        mode = cancel

        # time after which a subscriber / publisher is considered stale and eligible
        # for cancelation (see `akka.stream.subscription-timeout.mode`)
        timeout = 5s
      }

      # Enable additional troubleshooting logging at DEBUG log level
      debug-logging = off

      # Maximum number of elements emitted in batch if downstream signals large demand
      output-burst-limit = 1000

      # Enable automatic fusing of all graphs that are run. For short-lived streams
      # this may cause an initial runtime overhead, but most of the time fusing is
      # desirable since it reduces the number of Actors that are created.
      # Deprecated, since Akka 2.5.0, setting does not have any effect.
      auto-fusing = on

      # Those stream elements which have explicit buffers (like mapAsync, mapAsyncUnordered,
      # buffer, flatMapMerge, Source.actorRef, Source.queue, etc.) will preallocate a fixed
      # buffer upon stream materialization if the requested buffer size is less than this
      # configuration parameter. The default is very high because failing early is better
      # than failing under load.
      #
      # Buffers sized larger than this will dynamically grow/shrink and consume more memory
      # per element than the fixed size buffers.
      max-fixed-buffer-size = 1000000000

      # Maximum number of sync messages that actor can process for stream to substream communication.
      # Parameter allows to interrupt synchronous processing to get upsteam/downstream messages.
      # Allows to accelerate message processing that happening withing same actor but keep system responsive.
      sync-processing-limit = 1000

      debug {
        # Enables the fuzzing mode which increases the chance of race conditions
        # by aggressively reordering events and making certain operations more
        # concurrent than usual.
        # This setting is for testing purposes, NEVER enable this in a production
        # environment!
        # To get the best results, try combining this setting with a throughput
        # of 1 on the corresponding dispatchers.
        fuzzing-mode = off
      }
    }

    # Fully qualified config path which holds the dispatcher configuration
    # to be used by ActorMaterializer when creating Actors for IO operations,
    # such as FileSource, FileSink and others.
    blocking-io-dispatcher = "akka.stream.default-blocking-io-dispatcher"

    default-blocking-io-dispatcher {
      type = "Dispatcher"
      executor = "thread-pool-executor"
      throughput = 1

      thread-pool-executor {
        fixed-pool-size = 16
      }
    }
  }

  # configure overrides to ssl-configuration here (to be used by akka-streams, and akka-http – i.e. when serving https connections)
  ssl-config {
    protocol = "TLSv1.2"
  }
}

# ssl configuration
# folded in from former ssl-config-akka module
ssl-config {
  logger = "com.typesafe.sslconfig.akka.util.AkkaLoggerBridge"
}

rabbit-stats-bounded-mailbox {
  mailbox-type = "akka.dispatch.BoundedMailbox"
  mailbox-capacity = 10
  mailbox-push-timeout-time = 0s
}

sharding-dispatcher {
  type = Dispatcher
  executor = "fork-join-executor"
  fork-join-executor {
    parallelism-min = 4
    parallelism-factor = 2.0
    parallelism-max = 32
    parallelism-max = ${?DEFAULT_DISPATCHER_PARALLELISM_MAX}
  }
  # Throughput defines the maximum number of messages to be
  # processed per actor before the thread jumps to the next actor.
  # Set to 1 for as fair as possible.
  throughput = 5 # default is 5
}

//aggregator-internal-dispatcher {
//  type = Dispatcher
//  executor = "fork-join-executor"
//  fork-join-executor {
//    parallelism-min = 4
//    parallelism-factor = 2.0
//    parallelism-max = 32
//    parallelism-max = ${?DEFAULT_DISPATCHER_PARALLELISM_MAX}
//  }
//  # Throughput defines the maximum number of messages to be
//  # processed per actor before the thread jumps to the next actor.
//  # Set to 1 for as fair as possible.
//  throughput = 5
//}
//
//blocking-dispatcher {
//  type = Dispatcher
//  executor = "thread-pool-executor"
//  thread-pool-executor {
//    // or in Akka 2.4.2+
//    fixed-pool-size = 8
//  }
//  throughput = 100
//}
//
//enforcer-lookup-dispatcher {
//  type = Dispatcher
//  executor = "fork-join-executor"
//  fork-join-executor {
//    parallelism-min = 4
//    parallelism-factor = 2.0
//    parallelism-max = 32
//    parallelism-max = ${?DEFAULT_DISPATCHER_PARALLELISM_MAX}
//  }
//  # Throughput defines the maximum number of messages to be
//  # processed per actor before the thread jumps to the next actor.
//  # Set to 1 for as fair as possible.
//  throughput = 5
//}
